{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 787)\n",
      "(14000,)\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Auxiliary functions\n",
    "\n",
    "def onehot2cat(y:NDArray) -> NDArray:\n",
    "    '''Convert y in one_hot to categorical'''\n",
    "    return np.argmax(y, axis=1) \n",
    "\n",
    "\n",
    "def loadDataset(fn:str, toCat:bool=False) -> NDArray:\n",
    "    '''load dataset'''\n",
    "    with open(fn, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    X = data['X'] \n",
    "    if toCat: y = onehot2cat(data['Y'])\n",
    "    else:     y = data['Y'] \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def saveSKLModel(fn:str, model) -> None:\n",
    "    '''save SKLearn model as pickle'''\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "#load dataset\n",
    "\n",
    "fnt = 'wtdt-part.pickle'\n",
    "X, y = loadDataset(fnt, toCat=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators= 278, max_depth= 9, max_features= 'log2', min_samples_split= 6, min_samples_leaf= 1)\n",
    "model.fit(X,y)\n",
    "saveSKLModel(\"T1-randomForest.pickle\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9996\n",
      "Mean Feature Importance Variance: 0.0000\n",
      "Normalized Stability: 1.0000\n",
      "Feature Importance Balance (Entropy): 6.0871\n",
      "Combined Score: 0.8280\n",
      "0.827962947166482\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def objective_function(model, X, y, weight_accuracy=0.7, weight_stability=0.2, weight_class_penalty=0.1, target_class=None):\n",
    "    \"\"\"\n",
    "    Objective function that balances accuracy with feature importance stability and class-specific penalties.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The classifier model (e.g., RandomForestClassifier).\n",
    "    - X: The feature matrix.\n",
    "    - y: The target variable.\n",
    "    - weight_accuracy: Weight for accuracy in the final combined score.\n",
    "    - weight_stability: Weight for feature importance stability in the final score.\n",
    "    - weight_class_penalty: Weight for penalizing the performance on a specific class.\n",
    "    - target_class: The specific class you want to penalize (if any).\n",
    "    \n",
    "    Returns:\n",
    "    - Combined score based on accuracy, stability, and class penalty.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    importances_list = []\n",
    "    class_performance = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        # Train and validate the model\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        accuracy = model.score(X[val_idx], y[val_idx])  # Calculate accuracy on validation set\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Store feature importances\n",
    "        importances_list.append(model.feature_importances_)\n",
    "        \n",
    "        # Calculate performance on each class\n",
    "        if target_class is not None:\n",
    "            class_accuracy = np.sum(y[val_idx] == target_class) / len(val_idx)  # Accuracy for target class\n",
    "            class_performance.append(class_accuracy)\n",
    "\n",
    "    # Calculate mean and variance of feature importances\n",
    "    importances_array = np.array(importances_list)\n",
    "    variance_importances = np.var(importances_array, axis=0)\n",
    "    mean_variance = np.mean(variance_importances)  # Average variance across features\n",
    "\n",
    "    # Calculate the mean accuracy\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "\n",
    "    # Penalize the performance on the specific class\n",
    "    if target_class is not None:\n",
    "        mean_class_accuracy = np.mean(class_performance)\n",
    "        class_penalty = 1 - mean_class_accuracy  # Penalize lower performance on the specific class\n",
    "    else:\n",
    "        class_penalty = 0\n",
    "\n",
    "    # Normalize metrics to balance their scales\n",
    "    normalized_accuracy = mean_accuracy  # Accuracy is already on a normalized scale (0 to 1)\n",
    "    normalized_stability = 1 / (1 + mean_variance)  # Lower variance means better stability\n",
    "\n",
    "    # Combined score\n",
    "    combined_score = (weight_accuracy * normalized_accuracy) + (weight_stability * normalized_stability) - (weight_class_penalty * class_penalty)\n",
    "\n",
    "    # Print evaluation metrics for debugging\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "    print(f\"Mean Feature Importance Variance: {mean_variance:.4f}\")\n",
    "    print(f\"Normalized Stability: {normalized_stability:.4f}\")\n",
    "    print(f\"Class Performance (for target class): {np.mean(class_performance) if target_class else 'N/A'}\")\n",
    "    print(f\"Class Penalty: {class_penalty:.4f}\")\n",
    "    print(f\"Combined Score: {combined_score:.4f}\")\n",
    "\n",
    "    return combined_score\n",
    "\n",
    "# Example of using the function\n",
    "target_class = 3  # If you know which class is problematic\n",
    "combined_score = objective_function(model, X, y, weight_accuracy=0.7, weight_stability=0.2, weight_class_penalty=0.1, target_class=target_class)\n",
    "\n",
    "\n",
    "\n",
    "print(objective_function(model, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)\n",
    "saveSKLModel(\"T1-randomForest.pickle\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
